---
title: "lab_07"
author: "sean mussenden"
date: "8/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## About this lab

To complete this lab, you need to:
* write code in empty codeblocks provided to answer questions included (look for **Q**).
* write out the answer in the form of a complete sentence in the space given (look for **A**).

When you are finished, commit changes and push to your personal GitHub repo, then submit the URL to this document on ELMS.

## Load libraries and establish settings
**Task**: Load rvest, janitor and the tidyverse
```{r}
library(rvest)
library(tidyverse)
library(janitor)
# Turn off scientific notation
options(scipen=999)

# Load the tidyverse,rvest,janitor

```


Q1. How many individual cases has the U.S. Department of Justice filed against people accused of fraud related to the PPP or EIDL loan program, according to the DOJ website listing those cases: https://www.justice.gov/criminal-fraud/cares-act-fraud?  An example of one case that appears on this page is "U.S. v. Richard Ayvazyan et al". To answer this question, you will need to use rvest scrape the data on this single webpage into a dataframe that lists only case names. Hint: you will need to make use of html_elements() and html_text() -- a function that extracts text inside of an html tag -- for this.
A1.There are 89 individual cases from the U.S. DOJ for fraud.

```{r}
fraud_url <- "https://www.justice.gov/criminal-fraud/cares-act-fraud"
fraud_cases <- fraud_url %>%
  read_html() %>%
  html_elements("ul li b") %>%
  html_text()
  
fraud_cases %>%
  tibble()


  


```

Q2. In how many individual judicial districts has the U.S. Department of Justice filed cases against people accused of fraud related to the PPP or EIDL loan program, according to the DOJ website listing those cases: https://www.justice.gov/criminal-fraud/cares-act-fraud?  Note: an example of a judicial district is "Southern District of Florida". You will need to use rvest scrape the data on this single webpage into a dataframe.
A2. There are 28 individual judicial districts that the DOJ has fraud cases filed against. 

```{r}
fraud_url <- "https://www.justice.gov/criminal-fraud/cares-act-fraud"
judicial_districts <- fraud_url %>%
  read_html() %>%
  html_elements("p b i") %>%
  html_text()

judicial_districts <- judicial_districts%>% 
  tibble()

```

Q4. The website (https://www.justice.gov/criminal-fraud/cares-act-fraud) shows that the DOJ filed more cases in the Southern District of Florida than in any other district. One of those cases was filed against someone named "Diamond Blue Smith". Who is Smith, and what was he accused of, according to the criminal complaint? If you were an editor, would you have assigned a reporter to write a story about this case when the complaint was filed in court? Why or why not?
A4. Diamond Blue Smith is a Florida recording artist, who was charged in a COVID-19 fraud scheme. Smith was charged with wire fraud, bank fraud, and conspiracy to comitt both wire and bank fraud, because he was using money he got from PPP loans to buy items such as a Ferrari. He used false documents in order to obtain the money. I think I would have assigned a reporter to cover the story, just because he is a person in the media, and I think it is important to show that people who are seen as "famous" and may have a lot of money, can also be up to a lot of shady things. It is important for the public to know how these PPP loans are benefitting the public, as well as how people are using them in corrupt ways. 

Q5. In what percentage of all judicial districts has the U.S. Department of Justice filed cases cases against people accused of fraud related to the PPP or EIDL loan program, according to the DOJ website listing those cases: https://www.justice.gov/criminal-fraud/cares-act-fraud? In answering this question, you should also produce a list of judicial districts where DOJ has NOT filed a case, according to this site.  Note: to answer this question, you will need to scrape a table of all district courts on this up-to-date Wikipedia page under the heading "Active Courts": https://en.wikipedia.org/wiki/List_of_United_States_district_and_territorial_courts  
A5. 29.787% of judicial districts filed cases against people accused of fraud. 


```{r}
courts_url <- "https://en.wikipedia.org/wiki/List_of_United_States_district_and_territorial_courts"

  wiki_html <- courts_url %>%
httr::GET(config = httr::config(ssl_verifypeer = FALSE)) %>%
read_html() %>%
  html_table()
  
districts <- wiki_html[[3]] 

total_number_of_districts <- 94 

nrow(judicial_districts)/total_number_of_districts *100

  

  
  

  

```
Q6. What might explain why, according to this site, the DOJ has filed PPP-related fraud cases in less than half of the country's judicial districts?
A6. I think one of the reasons for the lack of reported fraud cases is because the DOJ mentioned they have to team up with other forces in order to prosecute and find fraudulent cases. Teaming up with outside organizations like attonerys, the FBI and the SBA, is probably why there is a delay in the efficiency of reporting. 

Q7. Which state had the most approved PPP loans per 100,000 population? [This web page](https://smussenden.github.io/coursefiles/ppp_scraping_example/index.html) has links to 52 individual web pages, one for each state (plus Washington, D.C. and Puerto Rico). Each of those web pages contains a one-row html table that has the name of the state, the number of approved loans, and the 2019 population. Here's an example for [Alabama](https://smussenden.github.io/coursefiles/ppp_scraping_example/states/alabama.html). You'll need to loop over the individual state urls, scrape each individual page and combine the information on each page into a single dataframe to answer this question.  
A7.SEE NOTES BELOW
```{r}
state_url <- "https://smussenden.github.io/coursefiles/ppp_scraping_example/index.html" %>%
  read_html %>%
  html_table()

state_urls <- state_url[[1]] %>%
  select(url) %>%
  as_vector()

state_information <- tibble()

for(url in state_urls){
  state_page <- url %>%
  read_html %>%
  html_table() 
  print(state_page)
  state_information <- state_information %>%
      bind_rows(state_page)
  state_information %>%
  
}

state_information %>%
  group_by(state) %>%
  summarise(count=n()
      ) %>%
  arrange(desc(population))
  
Okay well, I'm not sure now why it is not running because I know these are the steps you have to do to find the population.
  






```
